# =============================================================================
# Maestroverse Production Docker Compose Configuration
# =============================================================================
# This configuration is optimized for production deployment with:
# - Security hardening (non-root users, read-only filesystems where possible)
# - Resource limits to prevent resource exhaustion
# - Health checks for all services
# - Restart policies for high availability
# - Secrets management for sensitive data
# - Proper logging configuration
#
# Usage:
#   docker-compose -f docker-compose.prod.yml up -d
#
# Prerequisites:
#   - Create .env.production with production values
#   - Set up external secrets management (recommended)
#   - Configure reverse proxy (nginx/traefik) for SSL termination
# =============================================================================

version: '3.8'

services:
  # ===========================================================================
  # PostgreSQL Database
  # ===========================================================================
  postgres:
    image: postgres:15-alpine
    container_name: maestroverse-db-prod
    restart: unless-stopped  # Restart automatically unless explicitly stopped

    # Security: Read-only root filesystem where possible
    # Only /var/lib/postgresql/data needs to be writable
    read_only: true
    tmpfs:
      - /tmp
      - /var/run/postgresql

    # Security: Use environment file for secrets (or Docker secrets in swarm mode)
    env_file:
      - .env.production
    environment:
      # Security: Don't use default postgres user in production
      POSTGRES_USER: ${POSTGRES_USER:-maestro_prod}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:?Database password required}
      POSTGRES_DB: ${POSTGRES_DB:-maestroverse_prod}
      # Security: Disable PostgreSQL statistics collector for production
      POSTGRES_INITDB_ARGS: "--data-checksums"

    # Security: Only expose port to internal network (not to host)
    # Remove 'ports' section entirely for maximum security
    # Access database through application containers only
    # ports:
    #   - "5432:5432"  # Comment out in production!

    volumes:
      # Security: Use named volume for persistent data
      - postgres_data_prod:/var/lib/postgresql/data
      # Optional: Custom initialization scripts
      # - ./db/init-prod.sql:/docker-entrypoint-initdb.d/init.sql:ro

    networks:
      - maestro-internal

    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-maestro_prod}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

    # Security: Resource limits prevent DoS
    deploy:
      resources:
        limits:
          cpus: '2.0'      # Limit to 2 CPU cores
          memory: 2G       # Limit to 2GB RAM
        reservations:
          cpus: '0.5'      # Guarantee minimum 0.5 CPU
          memory: 512M     # Guarantee minimum 512MB RAM

    # Security: Logging configuration
    logging:
      driver: "json-file"
      options:
        max-size: "10m"    # Rotate logs at 10MB
        max-file: "3"      # Keep 3 log files

  # ===========================================================================
  # Redis Cache
  # ===========================================================================
  redis:
    image: redis:7-alpine
    container_name: maestroverse-redis-prod
    restart: unless-stopped

    # Security: Read-only filesystem
    read_only: true
    tmpfs:
      - /tmp

    # Security: Require password authentication
    command: >
      redis-server
      --requirepass ${REDIS_PASSWORD:?Redis password required}
      --maxmemory 512mb
      --maxmemory-policy allkeys-lru
      --appendonly yes
      --appendfsync everysec

    # Security: Don't expose port to host in production
    # ports:
    #   - "6379:6379"  # Comment out in production!

    volumes:
      - redis_data_prod:/data

    networks:
      - maestro-internal

    healthcheck:
      test: ["CMD", "redis-cli", "--pass", "${REDIS_PASSWORD}", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

    # Security: Resource limits
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M

    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ===========================================================================
  # Backend API Server
  # ===========================================================================
  server:
    build:
      context: ./server
      dockerfile: Dockerfile.prod
      # Security: Disable build cache in production for reproducible builds
      no_cache: true
    image: maestroverse-server:${VERSION:-latest}
    container_name: maestroverse-server-prod
    restart: unless-stopped

    # Security: Read-only filesystem except for uploads
    read_only: true
    tmpfs:
      - /tmp

    # Security: Use environment file
    env_file:
      - .env.production
    environment:
      NODE_ENV: production
      # Database connection
      DATABASE_URL: postgresql://${POSTGRES_USER:-maestro_prod}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB:-maestroverse_prod}?schema=public
      # Redis connection
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379
      # Security: JWT secret from environment
      JWT_SECRET: ${JWT_SECRET:?JWT secret required}
      # OAuth credentials
      GOOGLE_CLIENT_ID: ${GOOGLE_CLIENT_ID}
      GOOGLE_CLIENT_SECRET: ${GOOGLE_CLIENT_SECRET}
      GOOGLE_CALLBACK_URL: ${GOOGLE_CALLBACK_URL}
      GITHUB_CLIENT_ID: ${GITHUB_CLIENT_ID}
      GITHUB_CLIENT_SECRET: ${GITHUB_CLIENT_SECRET}
      GITHUB_CALLBACK_URL: ${GITHUB_CALLBACK_URL}
      # URLs
      FRONTEND_URL: ${FRONTEND_URL:?Frontend URL required}
      API_URL: ${API_URL:?API URL required}
      CORS_ORIGINS: ${CORS_ORIGINS:?CORS origins required}
      # Admin
      ROOT_ADMIN_EMAILS: ${ROOT_ADMIN_EMAILS}

    ports:
      - "${SERVER_PORT:-3001}:3001"

    volumes:
      # Security: Writable volume for file uploads (minimal permissions)
      - uploads_prod:/app/private-uploads

    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy

    networks:
      - maestro-internal
      - maestro-external

    healthcheck:
      test: ["CMD", "node", "-e", "require('http').get('http://localhost:3001/health', (r) => process.exit(r.statusCode === 200 ? 0 : 1))"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

    # Security: Resource limits
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M
      # High availability: Run 2 replicas (requires Docker Swarm or Kubernetes)
      # replicas: 2

    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"

  # ===========================================================================
  # Web Frontend (Next.js)
  # ===========================================================================
  web:
    build:
      context: ./apps/web
      dockerfile: Dockerfile.prod
      # Security: Pass API URLs as build args
      args:
        NEXT_PUBLIC_API_URL: ${NEXT_PUBLIC_API_URL:?API URL required}
        NEXT_PUBLIC_WS_URL: ${NEXT_PUBLIC_WS_URL:?WebSocket URL required}
      no_cache: true
    image: maestroverse-web:${VERSION:-latest}
    container_name: maestroverse-web-prod
    restart: unless-stopped

    # Security: Read-only filesystem
    # Next.js production build doesn't need write access
    read_only: true
    tmpfs:
      - /tmp
      - /app/.next/cache

    environment:
      NODE_ENV: production
      # Client-side environment variables
      NEXT_PUBLIC_API_URL: ${NEXT_PUBLIC_API_URL}
      NEXT_PUBLIC_WS_URL: ${NEXT_PUBLIC_WS_URL}

    ports:
      - "${WEB_PORT:-3005}:3000"

    depends_on:
      server:
        condition: service_healthy

    networks:
      - maestro-external

    healthcheck:
      test: ["CMD", "node", "-e", "require('http').get('http://localhost:3000', (r) => process.exit(r.statusCode === 200 ? 0 : 1))"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

    # Security: Resource limits
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 256M

    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"

# =============================================================================
# Volumes
# =============================================================================
# Security: Named volumes for persistent data
volumes:
  postgres_data_prod:
    driver: local
    # Optional: Use encrypted volume driver for sensitive data
    # driver_opts:
    #   encrypted: "true"

  redis_data_prod:
    driver: local

  uploads_prod:
    driver: local
    # Security: Restrict permissions on upload directory
    driver_opts:
      type: none
      o: bind
      device: ./private-uploads

# =============================================================================
# Networks
# =============================================================================
# Security: Separate internal and external networks
networks:
  # Internal network: Database and cache not exposed externally
  maestro-internal:
    driver: bridge
    internal: true  # No external access
    ipam:
      config:
        - subnet: 172.28.0.0/16

  # External network: API and web accessible from outside
  maestro-external:
    driver: bridge
    ipam:
      config:
        - subnet: 172.29.0.0/16

# =============================================================================
# Secrets (Docker Swarm mode)
# =============================================================================
# For production, use Docker secrets instead of environment variables
# secrets:
#   db_password:
#     external: true
#   jwt_secret:
#     external: true
#   redis_password:
#     external: true

# =============================================================================
# Production Deployment Checklist
# =============================================================================
# Before deploying to production:
#
# 1. Environment Configuration:
#    - Create .env.production with all required variables
#    - Never commit .env.production to version control
#    - Use strong, random passwords for all services
#
# 2. Security:
#    - Set strong POSTGRES_PASSWORD, REDIS_PASSWORD, JWT_SECRET
#    - Configure OAuth credentials for production domains
#    - Set proper CORS_ORIGINS (your production domain)
#    - Remove all debug/development settings
#
# 3. SSL/TLS:
#    - Set up reverse proxy (nginx/traefik) for SSL termination
#    - Use Let's Encrypt for free SSL certificates
#    - Configure HTTPS redirects
#
# 4. Database:
#    - Run database migrations: docker-compose exec server npm run db:migrate
#    - Create database backups schedule
#    - Set up monitoring for database performance
#
# 5. Monitoring:
#    - Set up log aggregation (ELK stack, Loki, etc.)
#    - Configure alerts for container health
#    - Monitor resource usage
#
# 6. Backups:
#    - Schedule regular backups of postgres_data_prod volume
#    - Test backup restoration procedures
#    - Store backups off-site
#
# 7. Updates:
#    - Keep Docker images updated
#    - Apply security patches promptly
#    - Test updates in staging environment first
# =============================================================================
